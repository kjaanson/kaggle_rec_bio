{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using https://www.kaggle.com/cyannani123/keras-cellular-image-classification as test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0,EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18023349260938755521\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, concatenate\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random,copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading test and train data.\n",
    "\n",
    "Will load directly from zip for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO, BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = zipfile.ZipFile('./input/recursion-cellular-image-classification.zip','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_data: (19899, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>experiment</th>\n",
       "      <th>plate</th>\n",
       "      <th>well</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-08_1_B03</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-08_1_B04</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-08_1_B05</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-08_1_B06</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-08_1_B07</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code experiment  plate well\n",
       "0  HEPG2-08_1_B03   HEPG2-08      1  B03\n",
       "1  HEPG2-08_1_B04   HEPG2-08      1  B04\n",
       "2  HEPG2-08_1_B05   HEPG2-08      1  B05\n",
       "3  HEPG2-08_1_B06   HEPG2-08      1  B06\n",
       "4  HEPG2-08_1_B07   HEPG2-08      1  B07"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(BytesIO(archive.read('test.csv')))\n",
    "print(\"Shape of test_data:\", test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_data: (19899, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>experiment</th>\n",
       "      <th>plate</th>\n",
       "      <th>well</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-01_1_B03</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B03</td>\n",
       "      <td>sirna_250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-01_1_B04</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B04</td>\n",
       "      <td>sirna_62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-01_1_B05</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B05</td>\n",
       "      <td>sirna_1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-01_1_B06</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B06</td>\n",
       "      <td>sirna_602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-01_1_B07</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B07</td>\n",
       "      <td>sirna_529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code experiment  plate well       sirna\n",
       "0  HEPG2-01_1_B03   HEPG2-01      1  B03   sirna_250\n",
       "1  HEPG2-01_1_B04   HEPG2-01      1  B04    sirna_62\n",
       "2  HEPG2-01_1_B05   HEPG2-01      1  B05  sirna_1115\n",
       "3  HEPG2-01_1_B06   HEPG2-01      1  B06   sirna_602\n",
       "4  HEPG2-01_1_B07   HEPG2-01      1  B07   sirna_529"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(BytesIO(archive.read('train.csv')))\n",
    "print(\"Shape of test_data:\", test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proovime kirjutada dataset-i faili.from azureml.core import Workspace, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laeme training data kõik mällu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retry import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(tries=3)\n",
    "def get_input(experiment, plate, well, site, channel, train=True):\n",
    "    \n",
    "    if train==True:\n",
    "        base_path = 'train'\n",
    "    else:\n",
    "        base_path = 'test'\n",
    "    \n",
    "    try:\n",
    "        path = f\"{base_path}/{experiment}/Plate{plate}/{well}_s{str(site)}_w{str(channel)}.png\"\n",
    "        img = Image.open(BytesIO(archive.read(path)))\n",
    "    except KeyError as err:\n",
    "        print(f\"Error loading input - {err}\")\n",
    "        print(\"Will default to other site\")\n",
    "        \n",
    "        # hack mis aitab kahe puuduva pildi puhul\n",
    "        # pm kui puudub pilt siis proovib lihtsalt teist saiti võtta\n",
    "        if site==2:\n",
    "            path = f\"{base_path}/{experiment}/Plate{plate}/{well}_s1_w{str(channel)}.png\"\n",
    "            img = Image.open(BytesIO(archive.read(path)))\n",
    "        else:\n",
    "            path = f\"{base_path}/{experiment}/Plate{plate}/{well}_s2_w{str(channel)}.png\"\n",
    "            img = Image.open(BytesIO(archive.read(path)))\n",
    "    \n",
    "    return(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sirna_label_encoder = LabelEncoder().fit(train_data.sirna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_namelist = archive.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_input(experiment, plate, well, site, channel, train=True):\n",
    "    if train==True:\n",
    "        base_path = 'train'\n",
    "    else:\n",
    "        base_path = 'test'\n",
    "        \n",
    "    path = f\"{base_path}/{experiment}/Plate{plate}/{well}_s{str(site)}_w{str(channel)}.png\"\n",
    "        \n",
    "    if path in arg_namelist:\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"{path} does not exist\")\n",
    "        return False\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saidid on samast wellist tehtud eri pildid. Pm võib võtta ainult ühe saidi sisse.\n",
    "Channelid on eri kanalitega tehtud pildid. Neid on kokku 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kirjutan piltide laadimise klassi notebooki näitel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgGen(Sequence):\n",
    "    def __init__(self, label_data, batch_size = 32, preprocess=(lambda x: x), shuffle=False):\n",
    "    \n",
    "        if shuffle:\n",
    "            self.label_data=label_data.sample(frac=1).reset_index(drop=True)\n",
    "        else:\n",
    "            self.label_data=label_data\n",
    "        \n",
    "        self.batch_size=batch_size\n",
    "        self.preprocess=preprocess\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.label_data))/float(self.batch_size))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        batch_x = self.label_data.loc[i*self.batch_size:(i+1)*self.batch_size,(\"experiment\",\"plate\",\"well\")]\n",
    "        batch_y = self.label_data.loc[i*self.batch_size:(i+1)*self.batch_size,(\"sirna\")]\n",
    "        \n",
    "        x_s1_c1 = [np.array(get_input(e, p, w, site=1, channel=1))/255 for e, p, w in batch_x.values.tolist()]\n",
    "        x_s1_c2 = [np.array(get_input(e, p, w, site=1, channel=2))/255 for e, p, w in batch_x.values.tolist()]\n",
    "        x_s1_c3 = [np.array(get_input(e, p, w, site=1, channel=3))/255 for e, p, w in batch_x.values.tolist()]\n",
    "        \n",
    "        x_s2_c1 = [np.array(get_input(e, p, w, site=2, channel=1))/255 for e, p, w in batch_x.values.tolist()]\n",
    "        x_s2_c2 = [np.array(get_input(e, p, w, site=2, channel=2))/255 for e, p, w in batch_x.values.tolist()]\n",
    "        x_s2_c3 = [np.array(get_input(e, p, w, site=2, channel=3))/255 for e, p, w in batch_x.values.tolist()]\n",
    "\n",
    "        x1 = np.array([x_s1_c1,x_s1_c2,x_s1_c3]).transpose((1,2,3,0))\n",
    "        x2 = np.array([x_s2_c1,x_s2_c2,x_s2_c3]).transpose((1,2,3,0))\n",
    "        \n",
    "        y = sirna_label_encoder.transform(batch_y)\n",
    "        \n",
    "        return [np.array(x1), np.array(x2)], y\n",
    "        \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImgGen(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.65 s ± 52.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit first_batch=train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-028750220060>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfirst_image_site1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_image_site1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_batch' is not defined"
     ]
    }
   ],
   "source": [
    "first_image_site1 = first_batch[0][0][0]\n",
    "plt.imshow(first_image_site1, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3afb8f3ae031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfirst_image_site2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_image_site2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_batch' is not defined"
     ]
    }
   ],
   "source": [
    "first_image_site2 = first_batch[0][1][0]\n",
    "plt.imshow(first_image_site2, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image augmentation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image):\n",
    "    random_transform = random.randint(-1,4)\n",
    "    if random_transform==0:\n",
    "        image = image.rotate(random.randint(-5,5))\n",
    "    if random_transform==1:\n",
    "        image = image.filter(ImageFilter.GaussianBlur(radius=1))\n",
    "    if random_transform==2:\n",
    "        image = image.filter(ImageFilter.RankFilter(size=3, rank=1))\n",
    "    if random_transform==3:\n",
    "        image = image.filter(ImageFilter.MedianFilter(size=3))\n",
    "    if random_transform==4:\n",
    "        image = image.filter(ImageFilter.MaxFilter(size=3))\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(512, 512, 3))\n",
    "    site1 = Input(shape=(512,512,3))\n",
    "    site2 = Input(shape=(512,512,3))\n",
    "    x = effnet(site1)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Model(inputs=site1, outputs=x)\n",
    "    y = effnet(site2)\n",
    "    y = GlobalAveragePooling2D()(y)\n",
    "    y = Model(inputs=site2, outputs=y)\n",
    "    combined = concatenate([x.output, y.output])\n",
    "    z = Dropout(0.5)(combined)\n",
    "    z = Dense(1108, activation='softmax')(z)\n",
    "    model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.025\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train_data, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set size {len(train)}\")\n",
    "print(f\"Validation set size {len(val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImgGen(train,batch_size=batch_size,preprocess=augment,shuffle=True)\n",
    "val_gen = ImgGen(val,batch_size=batch_size,preprocess=augment,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set batched size {len(train_gen)}\")\n",
    "print(f\"Validation set batched size {len(val_gen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'ModelCheckpoint_all.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [\n",
    "        ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen, \n",
    "                              steps_per_epoch=len(train)//batch_size, \n",
    "                              epochs=1, \n",
    "                              verbose=1, \n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=len(val)//batch_size,\n",
    "                              callbacks=callback\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
